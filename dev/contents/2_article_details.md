## 指示

あなたはOpenLearnという生成AIやプログラミングが学べるWebサービスの超優秀な編集者兼ライターです。
あなたのタスクは、次にこのプラットフォームに追加されるコース（下記で述べる「対象のコース」がそれに該当します。）の指定されたコースの記事を考えて作成し、出力することです。

## 対象のコース

下記に、今回対象とするコースの概要を示します。（コースは複数の記事から構成されています）

```
{
  "courseName": "また間に合う生成AI入門！大規模言語モデル（LLM）の概要と使い方を学ぶ",
  "courseId": "intro-to-llms",
  "articles": [
    {
      "articleName": "生成AIとLLMの基礎知識",
      "articleId": "basics-of-generative-ai-and-llms",
      "sequence": 0
    },
    {
      "articleName": "代表的なLLMモデル（GPTシリーズ・Gemini・Llama）の特徴比較",
      "articleId": "comparison-of-popular-llm-models",
      "sequence": 1
    },
    {
      "articleName": "プロンプトエンジニアリング入門〜良質な回答を引き出すコツ〜",
      "articleId": "prompt-engineering-basics",
      "sequence": 2
    },
    {
      "articleName": "OpenAI APIを使ってチャットボットを作ろう（Python編）",
      "articleId": "building-chatbot-with-openai-api-python",
      "sequence": 3
    },
    {
      "articleName": "LangChainを活用した高度なLLMアプリ開発",
      "articleId": "advanced-llm-app-development-with-langchain",
      "sequence": 4
    },
    {
      "articleName": "LLMのファインチューニング入門",
      "articleId": "introduction-to-llm-fine-tuning",
      "sequence": 5
    },
    {
      "articleName": "LLM活用のためのベストプラクティスと注意点",
      "articleId": "best-practices-and-tips-for-using-llms",
      "sequence": 6
    }
  ]
}
```

中でも、今回執筆してもらうのは、
{
"articleName": "生成AIとLLMの基礎知識",
"articleId": "basics-of-generative-ai-and-llms",
"sequence": 0
},
の記事です。

## 出力事項についての補足

OpenLearnにおけるコース記事出力にあたっては、

- コース記事本体（マークダウンで出力）
- 記事末尾の練習問題（jsonで出力）
  の2点を出力してもらいます。

### コース記事本体（マークダウンで出力）

コース記事は、下記ガイドラインに沿って、マークダウンで出力してください。

#### 概要記事作成のガイドライン

下記の内容を見出しなどに盛り込むと良いコース記事になりやすいです。
全部を無理やり入れる必要はないです。内容に応じて取捨選択してください。

- このコースで説明する概念はそもそも何なのか。どういう種類やパターン、類似のものがあるのか
- このコースで説明する概念を学ぶと何ができるようになり、どういうメリットがあるのか
- また類似のものと比較してどういうメリットとデメリットがあるのか
- 実際の現場などで活用する際にどういう問題が生じやすいか。またその対策は何か

※具体例や事例などを盛り込むようにしてください。
※もし必要であれば参考コードなどを入れても構いません。
※字数的には長めに書いてください。最低でも8000字いかないのはNGです。
※h1見出しはタイトルをそのまま出力してください。
※SEO上位表示させたい関係で、h2見出しにはこのコースの概念に関連するキーワードを積極的に盛り込んでください。
※専門用語を使っても構いませんが、高校生レベルで分からない単語は直後に()をつけて意味を説明するか、直後に「補足：例えばXXXでいうと、XXXのようなものです。」「補足：例えばXXXでは、XXXが出来ます」というような具体的な説明を加えてください。
※必要な場面では、積極的に固有名詞（開発者や重要なサービスなど）を入れても構いません。

## 記事作成の際の参考情報

参考までに、似たようなキーワードで検索したときに上位に出てくる記事をスクレイピングして掲載しておきます。
見出しや内容作成の参考にしてください。

<参考記事はじまり> \***_記事1_**
ビジネスの世界で注目を集めている「LLM（大規模言語モデル）」とは、膨大なテキストデータと高度なディープラーニング技術を用いて構築された、自然言語処理（NLP：Natural Language Processing）と呼ばれる分野における革新的な技術を指します。2024年12月には、OpenAI社の最新LLMモデルである「o3-mini」が発表され、さらに話題を集めています。

本記事では、具体的なビジネス活用の最新事情のほか、「ChatGPT」や「生成AI」などの関連ワードも交えて分かりやすく解説します。

INDEX
LLM(大規模言語モデル)とは
言語モデルとは
ファインチューニングとは
LLM(大規模言語モデル)と生成AIやChatGPTとの違い
生成AIとの違い
ChatGPTの違い
LLM(大規模言語モデル)の仕組み
STEP① トークン化
STEP② ベクトル化
STEP③ ニューラルネットワークを通した学習
STEP④ 文脈（コンテキスト）理解
STEP⑤ デコード（出力ベクトルに修正しテキストへ変換）
LLM(大規模言語モデル)の歴史
LLM(大規模言語モデル)の活用事例
NECの日本語LLM(大規模言語モデル)
LLM(大規模言語モデル)の課題
まとめ
創造しよう、想像を超えた未来を。NECソリューションイノベータはエンジニアのキャリア採用を強化しています。
メールマガジン登録 登録無料 申し込みはこちら 最新のIT動向 豊富なソリューション事例 いま話題のICT情報をお届けする
LLM(大規模言語モデル)とは
LLM（Large Language Models、大規模言語モデル）とは、膨大なテキストデータと高度なディープラーニング技術を用いて構築された、自然言語処理（NLP：Natural Language Processing）と呼ばれる分野における革新的な技術です。従来の言語モデルと比較して、「計算量（コンピューターが処理する仕事量）」「データ量（入力された情報量）」「パラメータ数（ディープラーニング技術に特有の係数の集合体）」という3つの要素を大幅に強化することで、より高度な言語理解を実現しています。

LLMはファインチューニングすることによって、テキスト分類や感情分析、情報抽出、文章要約、テキスト生成、質問応答といった、さまざまな自然言語処理タスクに適応可能となります。

言語モデルとは
言語モデルは、人間が話したり書いたりする「言葉」や「文章」をもとに、単語の出現確率をモデル化する技術です。具体的には、大量のテキストデータから学習し、ある単語の後に続く単語が、どのくらいの確率で出現するのかを予測します。たとえば、「私の職業は」という文章の後に続く単語として、「医者です」「SEです」「保育士です」は確率として高いと判断し、「黄色」「海」などは低いと判断していき、言語をモデル化していきます。こうして言語モデルは、単語の出現確率を統計的に分析することで、人間の言語を理解し、予測することができるようになります。

ファインチューニングとは
ファインチューニングとは、機械学習における用語で、微調整という意味です。具体的には、あるデータセットで学習済みのモデルを別のデータセットを使って再トレーニングし、新しいサービスやタスク向けに機械学習モデルのパラメータを微調整します。

LLM（大規模言語モデル）と生成AIやChatGPTとの違い
ここではLLMと、昨今話題の「生成AI」と「ChatGPT」の違いについて簡単に解説します。

生成AIとの違い
LLMと生成AIは、どちらも人工知能（AI）の一種ですが、階層と特化分野において異なる特徴を持っています。生成AIとは、テキスト、画像、音声などのデータを自律的に生成できるAI技術の“総称”です。一方、LLMは、自然言語処理に特化した“生成AIの一種”であり、膨大なテキストデータから学習することで、より高度な言語理解を実現したものです。

LLMと生成AIとの違い
関連情報

生成AIとは？
従来のAIとの違いや企業活用のメリットを解説

企業での活用が進んでいる「生成AI」。従来のAIとの違いや種類、メリット・デメリットを含めて解説します。

ChatGPTとの違い
LLMは大規模言語モデルのことを指しますが、ChatGPTはそのLLMを応用して、特に対話に特化した機能を持つAIモデル、あるいはこれを開発したOpenAI社の提供するサービスを示します。 LLMはあらゆる言語タスクに対応できる一方、ChatGPTはユーザーとの自然な会話を重視し、入力に対して適切な応答を生成することに最適化されています。新たなモデル「o3-mini」では、推論能力が大幅に向上し、高速な応答が可能となりました。

関連情報

ChatGPTとは？できることや活用事例などを分かりやすく解説

近年話題のChatGPTの意味やビジネスシーンでできること、企業での活用事例について分かりやすく解説しています。

LLM（大規模言語モデル）の仕組み
LLMがどのように言語を理解し、言葉を生み出すのか。大きく以下の5つのステップで解説できます。

LLM（大規模言語モデル）の仕組み
STEP① トークン化
トークン化とは、テキストデータをコンピュータが理解しやすいように、小さな言葉の塊であるトークンに分割する処理を指します。トークンとは、単語や句読点、記号など、テキストデータにおける最小単位の要素です。英語の場合、単語や句読点がトークンとなります。テキストデータはそのままではコンピュータが理解できないため、数値データに変換する必要があります。トークン化は、数値データに変換するための前段階として行われます。

トークン化は、LLMがテキストデータを理解し、処理するために必要な重要な技術です。トークン化によって、コンピュータがテキストデータを効率的に処理できるようになり、機械学習モデルの精度も向上します。

STEP② ベクトル化
ベクトル化とは、トークン化されたデータを数値のベクトルに変換する処理を指します。STEP①でも解説したように、トークン化によって分割されたデータは、そのままではコンピュータが解析できません。ベクトル化は、トークンを数値に変換することで、コンピュータが情報を解析できるようにするための処理です。ベクトル化によって、コンピュータがトークン（言葉の最小単位）を数値として扱うことができるようになり、より高度な言語理解を実現しています。

STEP③ ニューラルネットワークを通した学習
ニューラルネットワークは、LLMの核心的な部分であり、多数の層からなる複雑な構造を持っています。テキストデータがニューラルネットワークを通過する際に、各層でデータは変換され、調整されます。この過程でモデルは入力データの特徴を抽出し、学習を行います。また、ニューラルネットワークは、単語の出現確率だけでなく、単語間の関係性や文脈も考慮して学習するため、テキストデータの文脈やニュアンスを理解できるようになります。つまり、ニューラルネットワークによる学習によって、LLMは高度な言語処理能力を獲得できるのです。

STEP④ 文脈（コンテキスト）理解
文脈（コンテキスト）理解は、LLMがテキストデータを理解するために必要不可欠な機能です。ニューラルネットワークを通して入力されたテキストの文脈や背景を把握し、それに基づいて意味の解釈を行うため、LLMは単なる単語の並びではなく、文全体の意味や、文と文との関連性を理解できるようになります。

たとえば「私は川を渡るために橋を渡った」という文章の場合、LLMは文脈理解によって、「橋」が「箸」ではなく「川を渡るための構造物」であると判断できます。文脈理解は、LLMが人間に近い理解力と応答能力を発揮するために必要不可欠な機能。LLMは、文脈理解によって様々なタスクを実行できるようになるのです。

STEP⑤ デコード（出力ベクトルに修正しテキストへ変換）
テキスト変換は、LLM処理の最終段階であり、出力ベクトルを修正し、人間が理解できる自然なテキストデータに変換する作業です。LLM内部で処理していたベクトルデータを修正し、最も確率が高い単語やフレーズを選択することで、人間が理解できる自然なテキストデータの形に出力します。これによって、LLMは人間と自然なコミュニケーションをとれるようになるのです。なお、テキスト変換は「デコード」とも呼ばれます。

LLM（大規模言語モデル）の歴史
下表は、2018年以降のよりモダンなLLMについて、その概要の一部をまとめたものです。

発表年 企業名 LLM（大規模言語モデル）
2018 Google BERT
2020 OpenAI GPT-3
2021 Google LaMDA
2022 Google PaLM
2022 Meta LLaMA
2023 OpenAI GPT-4
2024 OpenAI GPT-4o
2024 OpenAI o1
2024 OpenAI o3-mini
・言語モデルは基本的にTransformerの仕組みを利用。

・Transformerとは、2017年に発表された「Attention Is All You Need」という論文で示されたディープラーニングのモデル。
従来の技術の仕組みを簡易化することにより、より早く制度の高い結果を出せるようになった新技術。

2024年12月には、新しいLLM「o3-mini」が公開されました。

なお、ほとんどの言語モデルは、基本的にTransformer（トランスフォーマー）と呼ばれるディープラーニングモデルの仕組みを利用しています（ChatGPTの「T」もTransformer）。Transformerは、2017年に発表された画期的な研究論文『Attention Is All You Need』で示された技術です。従来の技術と比べて処理を簡易化し、より迅速かつ高精度な結果を出せるようにしたことが特長で、昨今の急激なLLMの進化はこのTransformerが支えていると言っても過言ではないでしょう。

LLM（大規模言語モデル）の活用事例
LLMは、自然言語処理に特化したAIモデルです。そのため、言語を用いるあらゆる分野への活用が期待されています。たとえば、対話/文章要約/翻訳/入力の続きを予測/文章の分類や言い換え/キーワードの抽出/入力されたプログラムのコードなどのバグチェック/情報の抽出などにおいて有用とされており、ビジネス分野では以下のような用途に役立つとされています。

デジタル上でのユーザーとのコミュニケーション全般
IT分野での情報検索や意味解釈の補佐。文章の要約
マーケティング分野での広告のテキスト作成
議事録内容の抽出
もちろん、ビジネス活用以外にも社内向けの情報管理や教育など、さまざまな方面での活用が期待されています。

NECの日本語LLM（大規模言語モデル）
近年注目を集めている生成AIは、日本語処理において課題があるとも言われています。ビジネス利用する場合は、日本語に関する知識量及び文書読解力の点で高い性能が求められます。

NECが開発したLLMは、知識量に相当する質問応答や推論能力に相当する文書読解において世界トップレベルの性能を達成※1。高い性能を実現しつつパラメータ数を抑えることで、消費電力を抑制するだけでなく、軽量・高速のためクラウドおよびオンプレミス環境でも運用が可能になっています。
さらにNECは、高速性と高性能の両立を目指し、新たに「cotomi Pro」「cotomi Light」※2を開発。総合的なタスクに対する高い処理能力と応答までの時間短縮が両立可能となりました。NECの日本語LLMは日本語に特化しており、軽量で高性能なため、特に個人情報を扱う秘匿性の高い業務などでの活用が期待されています。

※1 2023年12月時点 NEC開発のLLM「cotomi」の比較評価表などはこちら

※2 「cotomi Pro」「cotomi Light」について

LLM（大規模言語モデル）の課題
LLMは様々な可能性を秘めていますが、いくつか課題も存在します。ひとつが「ハルシネーション」です。ハルシネーションとは、LLMが事実とは異なる情報や、文脈とまったく関係ない内容を出力してしまう現象です。日本語では「幻覚」と訳されます。ハルネーションには「Intrinsic Hallucinations」という学習に用いたデータと異なる事実を出力するケースと「Extrinsic Hallucinations」という、学習に用いたデータには存在しないことを出力するケースがあります。

ハルシネーションは、データ内に偏りや誤った情報が含まれている学習データの問題、モデルが誤った情報を生成しやすい構造・学習方法になっているAIモデルの学習プロセスなどの問題によって引き起こされます。ハルシネーションは、システムの進化と共に減っていくと考えられますが、言語モデルの性質上、完全な防止は難しいでしょう。そのため、ユーザーもハルシネーションが起こることを念頭においた上での利用が必要になります。

また、もうひとつ「プロンプトインジェクション」という問題も顕在化しています。プロンプトインジェクションとは、悪意のあるユーザーが巧妙なプロンプトを入力することで、LLMに本来禁止されている機能を実行させたり、不適切な回答をさせたりする攻撃手法。プロンプトインジェクションによって、企業の秘密情報や第三者の個人情報が開示されたり、根拠のないデマが拡散されたりするというリスクが発生します。

プロンプトインジェクションを防ぐには、入力できるプロンプトを制限するほか、出力結果をフィルタリングし、ユーザーに対してプロンプトインジェクションの危険性を啓蒙するやり方が考えられます。

LLMは、さまざまな可能性を秘めた技術ですが、ハルシネーションやプロンプトインジェクションなどの課題も存在します。これらの課題を克服するために、技術開発とユーザー教育の両面から取り組むことが重要です。

まとめ
かつては夢の技術と思われていたLLMですが、今や誰もが当たり前に利用できる一般的なビジネスツールとなっています。現実にすでに多くの企業がLLMを自社ビジネスに導入しており、すでに大きな成果を上げている事例も存在します。

見過ごせないリスクもまだまだ存在するLLMですが、これを無視して自社ビジネスをドライブさせるのは難しい時代になりつつあるといえるでしょう。まだLLMを利用していないが興味はあるという企業は専門家に相談し、どういった用途にLLMを利用できるか、そのために必要なことは何か、リスクを抑えるためにどうすればよいのかを見極めるところから初めてはいかがでしょうか？

\***_記事2_**
LLM(大規模言語モデル)とは？生成AIとの違いや活用事例・課題
データサイエンティスト
AI/機械学習
生成AI/LLM
執筆者
辻 陽行

公開日
2023.08.23
更新日
2024.12.02

こんにちは。株式会社ブレインパッドでデータサイエンティストを務める辻です。

本記事では、LLM（Large Language Model:大規模言語モデル）について基礎的な内容から応用領域まで網羅的に解説します。具体的には以下の内容です。

LLMの定義や概要・重要性
「LLM」と他関連ワードとの違い（「生成AI」「機械学習」との違いなど）
LLMを活用して実現できることや事例・モデル（ChatGPTなど）
LLMの課題と対策方法
LLMの今後の展望

下の目次の気になる箇所から読んでみてください。見出しの冒頭に【発展内容】と記載がある内容はより専門的な内容になっているので、難しい場合は読み飛ばしていただいても構いません。

※生成AIやLLMの台頭により激動となった2023年において、ビジネスパーソンによく読まれた記事ランキングを以下の記事にまとめました。よろしければこちらもご覧ください。
2023年にもっとも注目された生成AI＆DX記事

本記事の執筆者

データサイエンティスト
辻 陽行
HARUYUKI TSUJI
会社
株式会社ブレインパッド
所属
アナリティクスコンサルティングユニット
役職
マネジャー
機械学習を用いた需要予測や判別問題に関する事例を担当。プロジェクトの立ち上げから機械学習アルゴリズムの仕組み化の支援までを主に担当。
目次
LLM（大規模言語モデル）とは？概要や定義
LLMが注目されている理由
「LLM」と類似用語との違い
「LLM」と「生成AI」「自然言語処理」との違いは？
「LLM」と「機械学習」との違いは？
LLMの実行可能なタスクや実現できること
LLMを活用したモデル一覧
企業におけるLLMの活用事例や身近な例
事例1.情報検索・情報の意味付けのサポート
事例2.クリエイティブ制作や広告・マーケティングのサポート
事例3.教育や学習のサポート
事例4.オペレーション業務の効率化
【発展内容】LLMの課題と対策法
LLMの課題は「出力の制御」
対策1.コンテンツモデレーション
対策2.ガードレール
LLMが大きなインパクトを与える分野
教育分野
ビジネス分野
エンターテイメント分野
【発展内容】生成AI・LLM技術に関する最新トレンド
【発展内容】LLMの今後の発展や期待される未来
データ量と質の向上
モデルサイズと性能の向上
倫理性と責任性の向上
LLMのビジネス活用の流れ
まとめ
LLM（大規模言語モデル）とは？概要や定義
LLMの仕組みを表した図
LLM（大規模言語モデル）は、自然言語処理（NLP）の分野で使用される深層学習モデルの一種であり、その主な目的は、膨大な量のテキストデータを学習し、人間のような自然な言語生成や理解を実現することです。

技術的な側面からもう少しお話すると、LLMは深層学習の技術を用いた複雑なモデルで、その基盤となるのはニューラルネットワークと呼ばれる人間の脳のニューロンの働きを模倣する計算モデルです。

このニューラルネットワークは、複数の層からなる構造で入力データを受け取り、パターンを学習して予測や分類を行うことができます。特に、LLMは巨大なテキストデータを入力とし、大量のパラメータを調整しながら言語構造を学習させています。

代表的なLLMの例として

Googleの「PaLM」
OpenAIの「ChatGPT」
オープンソースなモデルとしてMetaが開発した「Llama」、Databricksが開発した「Dolly」
などがあります。

PaLMやChatGPTやLlamaは、人間の文章とほぼ同レベルの流暢さと論理性を持ったテキストを自動的に生成できるモデルです。これらのモデルは数十億ものパラメータから成る巨大なニューラルネットワークで、膨大な量のテキストデータから学習を行っています。

【関連記事】
ChatGPTとは？使い方・始め方・仕組み・最新の活用事例を一挙ご紹介！

LLMは機械翻訳やテキスト要約、対話システムなどの自然言語処理の主要なタスクに向いており、近年では人間並みの性能を発揮できるレベルに到達してきています。

LLMが注目されている理由
LLMが最近注目されるようになった理由は、「これまでのAIでは到達するのが難しいと考えられていた人間の言語能力」に匹敵する性能を示し始めたためです。

※そもそも「AI（人工知能）」の定義を明確にしたい方は、以下の記事もあわせてご確認いただければと思います。
【関連記事】
入社1年目が教わる「はじめての人工知能」　第1回：人工知能（AI）とはなにか

自然言語は極めて複雑で、人間は赤ちゃんの頃から段階的に経験を通じて習得します。対してLLMは人間の言語獲得プロセスを模倣することで、人工知能システムに高度な言語スキルを、人間が言語を習得するよりもはるかに短い時間で身に付けさせます。

これまでもAIを用いたChatBotが開発されたり多言語翻訳のためのモデルが開発されたりと、AIに関連する技術自体は着実に進歩を続けていたのですが、LLMの出現によってそこからさらに圧倒的な進歩を遂げました。

これまでのAI技術では実現が難しいとされていた「人間との自然な対話・応答」がLLMによって実現が可能になったことで、大きな注目が集まるようになったのです。

「LLM」と類似用語との違い
最近、AI関連の技術用語がメディアなどで頻繁に登場するようになりました。その中でも、LLMに似た用語である「生成AI」「自然言語処理」「機械学習」は、LLMとの違いがいまいちよく分からない方も多いと思います。

これらの用語は確かにLLMと関連はしていますが、意味するところは異なりますので、それぞれ簡潔に違いを説明します。

「LLM」と「生成AI」「自然言語処理」との違いは？
LLMは、前述した通り「膨大なテキストデータから言語のパターンを学習し、テキスト生成や要約などのテキストに関わるタスクを高い精度で行うことができる深層学習モデル」です。

一方、生成AIは、テキスト・画像・音声などを自律的に生成できるAI技術の総称であり、その生成プロセスはRNN、GAN、Diffusionなど多様に存在します。LLMは生成AIの中でも特に自然言語処理を担うモデルと位置づけられます。

「LLM」と「生成AI」「自然言語処理」との違い
「LLM」と「生成AI」「自然言語処理」との違い
つまりLLMは、生成AIと呼ばれるモデルの中の一つなのです。

【関連記事】
生成AI（ジェネレーティブAI）とは？仕組みやChatGPTとの関連性を解説

ちなみに自然言語処理（NLP:Neuro Language Programmingとも呼ばれます）はコンピュータに人間の言語を理解・処理させる技術を指します。機械翻訳や文書要約など多岐にわたる応用があります。

LLMは自然言語処理タスクを解決する生成AIと見なすことができます。

「LLM」と「機械学習」との違いは？
「LLM」と「機械学習」の立ち位置を簡単に説明すると、「LLM（生成AIの一種）」は「機械学習」の一種です。

機械学習は、統計学やデータマイニング手法を使ってコンピュータにデータから学習する能力を持たせ、未知のデータに対して予測や判断を行わせる技術のことです。データを入力し、そこから統計的なパターンや特徴を抽出することで、モデルを構築します。

このモデルを用いることで、新しい入力データに対する分類や回帰などのタスクを実行できるようになります。

「LLM」と「機械学習」との違い
「LLM」と「機械学習」との違い
【関連記事】
機械学習とは？3つの学習手法と知っておきたい活用事例
入社1年目が教わる「はじめての人工知能」 第5回：人工知能（AI）を支える「機械学習」の全体像

深層学習や生成AIは機械学習の応用分野の一つではあるのですが、その中でも画像認識や音声認識、会話の要約など従来の機械学習モデルではうまく対応できなかったタスクを解決できるようになってきたため、現在注目を集めています。

LLMの実行可能なタスクや実現できること
LLMはプロンプト（指示を送ること）によって、テキストに関わるタスクを高い精度で実行してくれます。以下はその例です。

文章の作成・要約・校正・言い換え
文章の分類
質問に対する回答・チャット
情報の検索・抽出
プログラムのコードチェック・バグチェック
多言語翻訳
このように、これまで人間しか行うことができないと思われていたテキストに関わるあらゆる処理が可能になってきています。

文章の要約の例を挙げると、膨大なドキュメントを短時間で読み込まなければならない場合、テキストデータをLLMに与え「この文章を要約してください」と指示を出します。すると、読み込む必要のある文章のうち重要な部分を抽出して提示してくれるため、従来よりも効率的に内容を理解できるようになります。

LLMを活用したモデル一覧
LLMを活用したモデルの一部をご紹介します。

モデル名 開発組織 発表年 商用利用可否
GPT-4 OpenAI 2023 可
MPT-7B MosaicML 2023 MPT-7B：可 (Apache-2.0)MPT-7B-Instruct：可（cc-by-sa-3.0）MPT-7B-Chat：不可（cc-by-nc-sa-4.0）MPT-7B-StoryWriter：可（Apach-2.0）
Llama Meta 2023 モデル：不可コード：可（GNU General Public License v3.0）
Alpaca Stanford Univ. 2023 モデル：不可Dataset：不可(CC BY NC 4.0)コード：可（Apach-2.0）
Vicuna UC Berkeley 2023 モデル：不可コード：可（Apache-2.0）
Lit-LLaMA Lightning-AI 2023 モデル：不可コード：可（Apache-2.0）
UL2(Flan-UL2) Google 2023 可
Dolly-2.0 Databrics 2023 モデル：可（MIT）データセット：可（CC BY SA 3.0）
Jurassic-2 AI21 labs 2023 可
例えばOpenAI社が開発した言語モデル「GPT-4」や「GPT-3」は、すでに多くの人たちに利用されている「ChatGPT」に使用されています。

企業におけるLLMの活用事例や身近な例
ここからはLLMの具体的な活用例についてご紹介します。

従来の機械学習やAIは、生産性向上のための業務効率化や自動化を中心に展開され、RPA（Robotic Process Automation）による定型業務の自動化、需要予測、予防メンテナンスなどの具体的なタスクでの活用が主流でした。

しかし、LLMの登場によって、AIの活用領域は大きく変わりつつあります。

LLMは、従来の機械学習モデルが価値を発揮していた特定タスクの効率化・自動化という限定的な活用領域を超え、「収益機会の最大化」や「個別化された顧客体験の提供」など、より多岐に渡るビジネス価値を生み出すことが可能となっています。LLMの活用の可能性は広がりを見せており、比較的早期に導入が進むと見込まれている領域がいくつか存在します。以下、その事例と共に詳しく解説していきます。

【関連記事】
生成AI・LLMをビジネス適用するための検討ポイントおよびユースケース

事例1.情報検索・情報の意味付けのサポート
ビジネスにおいて最初にLLMの恩恵を最も享受する領域は、この情報検索領域だと考えられます。

例えばミーティングで作成される「議事録」を読み返そうとしたとき、基本的には議事録ファイルを手動で開き、何が書かれているのかを都度確認する必要があります。これまではそれが当然でした。

しかしLLMを活用すると、膨大な議事録データから、その人が読み返したい必要な情報のみを取得してくれるようになります。これにより、情報検索のコストが大幅に削減されることが期待されます。

例えば、あるプロジェクトの進捗状況や課題点を第三者が把握したいと思った場合、LLMにそのプロジェクト名や関連キーワードを伝えるだけで、LLMはそのプロジェクトに関する過去の会議内容や議事録から必要な情報を抽出し、要約して提示してくれます。

海外のAIスタートアップ企業であるPineConeやOpenAI、Google CloudやAWSのようなメガプラットフォーマーなどもこのベクトル検索やEmbbeding検索と呼ばれる情報検索機能をサービスとして続々と提供し始めています。

事例2.クリエイティブ制作や広告・マーケティングのサポート
広告や記事の作成を行う際に、LLMが今後サポートを行う可能性が大きく高まってきています。

これまでは人間の手によって、広告のコピーや画像の作成を全て実施してきました。

しかしこれからは、LLMが文章案を作成し、Stable Diffusionのような画像生成AIがイメージ案を作成することで、人間のクリエイティブ作成作業を効率化できるようになっていくと考えられます。

例えば、ある商品の広告文の作成業務にあたるとしましょう。

LLMに商品名やターゲット層、キャッチコピーなどのキーワードを与えることで、LLMはその商品コンセプトに適した広告文を生成してくれます。

そしてStable Diffusionに広告文と商品名を与えることで、その商品に合った魅力的な画像が生成されます。

※ただし、実際の活用を考えるとLLMやStable Diffusionが商品情報を正しく表現できる必要があるため、LLMに対してドメイン適応と呼ばれる工夫を加える必要があります。

また、生成AIのスタートアップ企業であるRunwayは、画像編集や動画編集に特化した生成AI技術を普及させるためのプロダクトを提供しており、その活用事例としてCBSやTopGearのようなテレビ番組、コマーシャルでの活用が進んでいます。

同社の公式サイトによると、映画監督兼編集技師が実際にRunwayのサービスを用いてフィルム、ミュージックビデオ、コマーシャルを制作しており、生成AIが新しい創作手法として注目されています。

【参考】How director and editor Evan Halleck uses Runway for films, music videos, and commercials

事例3.教育や学習のサポート
知識の習得には書籍や教育機関（学校など）による学習が一般的ですが、これまでの学習教材は、自分が理解できなかった部分に対して自動で補足説明してくれることはありませんでした。

また、学習を進めながら「専門的な理解をさらに深めたいと思った領域」を発見しても、その領域に関する教材に関しては自ら探しにいくか、適切な教師に聞きにいく必要がありました。

しかし、LLMは教育や新たな知識獲得のサポートを今後大きく担ってくれる可能性があります。

例えば「数学」について学びたいと思った時、LLMに数学を学びたい旨と数学の現状の理解度・興味度などを伝えるだけで、LLMはその人に最適な教材や参考資料を提供してくれます。

それだけでなく、LLMはその人が学習した内容や理解度のレベルを把握し、必要に応じて補足説明や問題演習なども行ってくれます。

さらに、LLMはそれまでの学習過程を通じて「その人が興味ありそうな関連科目」や「深掘りしたくなる可能性があるトピック」なども提示してくれるようになるので、自分のペースで好きなだけ学ぶことができます。

弊社ブレインパッドでも、プロトタイプ的に学習支援ツールを社内導入しています。

【参考】ChatGPTのAPIを使って、学習用ドキュメント生成ツール作ってみた

事例4.オペレーション業務の効率化
最後に、電話によるカスタマーサポートのオペレーション業務の事例を取り上げてみたいと思います。LLMは、カスタマーサポート体験の質を大きく向上させる可能性があります。

従来のようにカスタマーサポートへの問い合わせ手段が電話で、かつサポートの担当者が人間である場合、24時間の対応が難しかったり、サポートの質が担当者の質に大きく依存したり、顧客の問い合わせ分析を定量的に実施できないといった不都合が生じるケースが多くありました。

しかしここに、LLMが活用された24時間対応可能なカスタマーサポートチャットボットが実装されると、消費者の問い合わせ内容の分析と適切な応答・解決策の洗い出し・定型業務の効率化が実現され、過大な人件費を抑制しながらサポート業務の質を保ちつつサービスを展開できる可能性があります。

また、チャットボットの精度が上がれば上がるほど、顧客のニーズや要望に柔軟に対応できるようになるため、結果的に顧客満足度の向上にも繋がります。

このように、LLMの活用により企業は、消費者とのエンゲージメントを高めながら生産性と収益力を飛躍的に向上させることが可能になってきています。人とAIが協調しながら業務を遂行することで、企業はこれまでにないレベルの効率性と創造性を発揮できるようになっていくでしょう。

【発展内容】LLMの課題と対策法
ここまではLLMの活用の可能性や有用性についてお話ししてきましたが、LLMを本格的に社会の中で浸透させていくには、乗り越えなければならない課題が存在していると考えています。

LLMは、自然言語を理解し、生成することができる革新的な技術です。これらの技術は、様々な分野で活用される可能性がありますが、同時に慎重に扱わなければならない課題も抱えています。

ここからは、LLMの活用における課題の一つである「出力の制御」について考察します。

LLMの課題は「出力の制御」
LLMは、人間の言語を模倣することができますが、それゆえに人間が意図しない内容を出力することもあります。

例えば、不適切な言葉や偏見を含む文章を生成したり、著作権を侵害するような画像や事実と異なる情報を生成したりすることがあります。これらの出力によって、LLMを利用する企業や組織の信頼性や評判が損なわれるだけでなく、社会的な問題を引き起こす可能性もあります。

そこで、生成AIやLLMの出力を制御する方法が必要になります。

対策1.コンテンツモデレーション
LLMの出力の制限対策である一つの方法は、コンテンツモデレーションと呼ばれる技術です。コンテンツモデレーションとは、LLMの出力を事前にチェックし、不適切な内容を検出し、削除や修正することを指します。

コンテンツモデレーションは、人間の手作業や自動化されたシステムのどちらでも行うことができますが、どちらにもメリットとデメリットがあります。

人間の手作業は、精度が高く文脈に応じた判断ができますが、コストや時間がかかります。自動化されたシステムは、コストや時間を節約できますが、精度が低く、文脈に応じた判断が難しい場合があります。

対策2.ガードレール
もう一つの方法は、ガードレールと呼ばれる制約です。

ガードレールとは、LLMに対して、出力すべき内容や形式をあらかじめ指定することです。例えば、「政治的な発言はしない」「暴力的な表現は使わない」「文法的に正しい文章を書く」などのルールを設定することです。

ガードレールは、LLMに対して明確な指示を与えることで、出力の品質や安全性を向上させることができます。

しかし、ガードレールも完璧ではありません。ガードレールが過剰に厳しすぎると、LLMの創造性や多様性を阻害することになります。

逆に、ガードレールが過剰に緩すぎると、LLMの出力が不適切になる可能性があります。

LLMは素晴らしい技術ですが、一方でその出力を制御する方法はまだ確立されていません。LLMの活用においては、コンテンツモデレーションやガードレールなどの技術を適切に使い分けることが重要です。

また、LLMの開発者や利用者は、その技術の可能性だけでなく「責任や倫理」も考慮することが求められます。LLMは、人間の言語を理解・生成できる技術ですが、それゆえに人間の言語を尊重し、保護することができる革新的な技術であるべきです。

LLMが大きなインパクトを与える分野
LLMが今後どのような分野に対して大きなインパクトを与えるかについて、前述した活用事例と重複する部分がありますが、以下のように考察しています。

教育分野
ビジネス分野
エンターテイメント分野
教育分野
教育分野では、LLMは学習者のニーズに応じてカスタマイズされた教材やフィードバックを提供できます。先ほどの「LLMの活用事例や身近な例」の章でも言及しましたが、学習者のレベルや興味に合わせて、最適な文章や問題を生成したり、学習者の回答や作文に対して具体的なアドバイスや評価の提供が可能になります。

また、LLMは多言語に対応できるため、異なる言語や文化の学習者同士のコミュニケーションや交流を促進することも可能となるでしょう。

ビジネス分野
ビジネス分野では、LLMは様々な業務や複合的なタスクの効率化・自動化を可能にします。

例えば、LLMは顧客の要望や質問に応じて適切な回答や提案を生成したり、膨大なデータや文書から重要な情報や知識を抽出したり、新しいアイデアや戦略を創造したりすることができます。

また、LLMはビジネスパートナーや競合他社の動向・傾向を分析したり、将来の市場や需要を予測したりすることもできるようになる可能性を秘めています。

エンターテイメント分野
エンターテイメント分野では、LLMは個々人の趣向に合わせたサービスを提供することで生活を豊かにすることができる可能性があります。

例えば、LLMは人々の好みや感情に応じてオリジナルのストーリーや詩や歌詞を生成したり、人気のある作品やキャラクターのパロディーや続編を作成したりすることが技術的には可能になってきています。

また、LLMは人々と自然な会話やゲームを楽しんだり、ユーザーの好みに合わせた表現や情報を提供したりすることもできるようになるでしょう。

【発展内容】生成AI・LLM技術に関する最新トレンド
LLM、および生成AIに関する技術革新は日々進んでおり、それを取り巻く社会情勢もめまぐるしく変化しています。

これらの技術の社会実装に向けた取り組みや企業への支援を強化するため、ブレインパッドではLLM/生成AIに関する技術調査プロジェクトが進行しており、最新トレンドの継続的なキャッチアップを行っています。

ここではプロジェクトの勉強会から、ビジネスに関わりの深いLLM・生成AI最新トピックを取り上げ、AI活用の現場に携わるコンサルタントが解説した連載記事をご紹介します。

ビジネスパーソンが押さえておきたい 生成AI/LLM技術最新トレンド
【Vol1】OpenAIの日本法人開設…他
【Vol2】Llama3公開、 RAGモデルの信頼性…他
【Vol3】GPT,Gemini,KAN,AlphaFold3など
【Vol4】Grounding DINO 1.5 Pro/Edge公開…他
【Vol5】言語モデル評価のベストプラクティス…他
【Vol6】Googleの AI Overview ハルシネーション防止策…他
【Vol7】RAG手法 MRAG…他
【Vol8】松尾研の構想…他
【Vol9】Claude 3.5 Sonnet リリース,EAGLE-2…他
【Vol10】LLMの長文理解を評価するベンチマーク,LLM-CriticGPT…他
【Vol11】モデルから知識を”忘却”する技術…他
【Vol12】GPT-4o mini 登場,スプレッドシートの構造の読み取り…他
【Vol13】OpenAI o1、OpenAI o1-mini発表…他
【Vol14】ストレスレベルがLLMのパフォーマンスへ影響…他
【Vol15】AIが映像を「見て学び」、ロボットに「実行させる」…他
【vol.16】スマホ利用可の高性能AIが登場…他
【vol.17】複数のAIエージェントが協力し合って複雑な作業に挑む…他
【発展内容】LLMの今後の発展や期待される未来
最後に、LLMがどのような進化を遂げるかについて考察を述べて、本記事を締めさせていただこうと思います。

LLMの今後の進化についてですが、私は以下の三つの点でさらなる発展が見込まれると考えています。

データ量と質の向上
モデルサイズと性能の向上
倫理性と責任性の向上
データ量と質の向上
LLMは大量のテキストデータを学習することで、自然言語処理のさまざまなタスクに対応できるようになります。

しかし、データ量だけではなく、データの質も重要です。

例えば、多様なジャンルやドメイン、言語、文化、時代などのデータを取り入れることで、LLMはより幅広い知識や文脈を獲得できます。また、データに含まれるバイアスや誤りを排除することで、LLMはより正確かつ公平な予測や推論を行えます。

また、LLMは基本的に「WEB上で収集可能なデータ」を用いて学習を行っているため、企業の機密情報や個人間の人間関係のような「WEBからは収集できない情報」に対する適切な回答は困難です。それを克服するためには、企業や個人の固有の状況や情報を踏まえて、適切に対応できるようなデータを集めてLLMを再学習させるための工夫も必要になってきます。

この「WEBから収集できない情報を学習させる技術」について例を挙げると、「ファインチューニング」があります。ChatGPTに社内文書を学習させ、社内情報をアウトプットしてくれるような仕組みの実装が可能です。これは通常のChatGPTでは実現不可能です。

以下の記事では、ChatGPTのファインチューニング実装について具体的に解説しています。あわせてご覧ください。

【関連記事】
社内文書に特化したChatGPT　ファインチューニング実践編

モデルサイズと性能の向上
LLMはパラメータ数が多いほど、より複雑な言語現象を捉えられると言われています。実際に、近年では数十億から数兆個のパラメータを持つ巨大なLLMが開発されており、驚異的な性能を示しています。

しかし、モデルサイズの増加は計算コストやメモリ消費も増加させるため、効率的な学習や推論の方法が求められます。また、実際のビジネス適用を考えると「人間なら数秒で終わるような応答が、LLMでは数分かかる」ような状態になってしまえば、導入はたちまち困難になります。

サービス品質の観点でも、LLMの推論の効率化は重要なトピックと考えられています。

例えば、量子化(*1)や蒸留(*2)と呼ばれる学習や推論の効率化技術を用いることで、LLMの性能を落とさずにモデルサイズを圧縮させる技術が日々発展してきています。

\*1：量子化とは、モデルのパラメータ数や計算負荷を削減する一つの技術手法です。

\*2：蒸留とは、すでに学習済みのモデルを模倣する一つの技術手法です。

倫理性と責任性の向上
LLMは人間の言語や知識を反映するだけでなく、人間の価値観や判断も影響を受けます。そのため、LLMは倫理的に問題のある内容を生成したり、人間に悪影響を及ぼしたりする可能性があります。

例えば、LLMは偏見や差別、虚偽や誇張などの不適切な言葉を使ったり、人間のプライバシーやセキュリティを侵害したりする恐れがあります。

これらの問題に対処するためには、LLMの開発者や利用者は倫理性と責任性を持って行動する必要があります。どんな行動かと言いますと、LLMの目的や制限を明確にし、適切な評価や監視を行い、問題が発生した場合には迅速に対応することが挙げられます。具体的には前述したコンテンツモデレーションやガードレールといった技術をさらに発展させていく必要があります。

LLMのビジネス活用の流れ
LLMのような生成AIのビジネス活用を検討するうえで、「何から始めればいいかわからない」という方は多いと思います。

生成AIをビジネス活用に落とし込むまでの流れはいくつかあると思いますが、ここでは、データサイエンスの専門家集団として生成AIの技術探求のみならず、実用化に向けた壁を突破するために必要な知見を蓄積してきたブレインパッドが、2023年8月に提供を開始した「生成AI／LLMスタータープラン」に沿って、説明していきます。

本プランではビジネス活用の流れを以下のように設定しています。

生成AI／LLMスタータープラン
スタータープランは、「まず簡易に試したい」というお客様のニーズに応えるリーズナブルかつスピーディな環境構築プランです。約1か月間で生成AIの利用環境を構築し、チャット画面を用いた簡易機能を実際に操作することが可能です。

生成AIのビジネス活用を考慮する場合、まずは生成AIの活用イメージを膨らませることが重要です。

また、生成AI／LLM活用の勘所をつかんでいただいた方は、アドバンスプランを通して

ビジネス課題やデータ環境のアセスメント
最新事例をふまえた生成AI施策案の提示
ロードマップ策定
生成AI利用環境拡張
ファインチューニング
ガードレール構築
といった、生成AIの本格的なビジネス活用施策を具体化する「ロードマップ策定」、もしくは施策を実行に移す「本格システム実装」いずれかのサービスを利用いただけます。

生成AI／LLMスタータープラン
まとめ
AI技術はこれまで着実に進歩を遂げてきましたが、LLMによる技術進歩は従来の発展と比べると遥かに大きく、一つのパラダイムシフトを迎えたと言っても過言ではないかもしれません。

しかしその革命的な技術の裏にはまだまだ課題も多く、ビジネス適用には数々の壁が立ちはだかることと思います。あくまでLLM活用は手段の一つであり、目的に適した活用であるかどうかの見極めは重要だと言えるでしょう。弊社ブレインパッドでも生成AIやLLMのビジネス活用は徐々に支援させていただいておりますので、ビジネス活用に際するご相談やお悩みがあればお問い合わせいただければと思います。

\***_記事3_**
＜この夏読みたい生成AIシリーズ第1回＞まずはここから！生成AIとLLM、ChatGPTの基礎知識
ChatGPT 生成AI
はてなブックマーク
Pocket
2024.08.05

「この夏読みたい生成AIシリーズ」では、生成AIの概要や最新の動向にはじまり、実際のマーケティング業務での活用方法まで順を追ってご紹介します。毎日忙しく勉強する時間がなかなか確保できなかったビジネスパーソンにおすすめしたい連載コンテンツです！
第1回では、2023年の流行語にも選ばれた「生成AI」「ChatGPT」という2つのキーワードに注目して、生成AIサービスの基礎知識について順番に解説します。

＜この夏読みたい生成AIシリーズ＞
第１回：まずはここから！生成AIとLLM、ChatGPTの基礎知識（本コラム）
第２回：生成AIの今後がわかる！米国ビッグテック企業と生成AI競争
第３回：覚えるだけじゃ使えない！プロンプトの極意『FOCUSプロンプト』とは
第４回：どこまでできる？マーケティングへの活用例（前編）
第５回：どこまでできる？マーケティングへの活用例（後編）
第６回：ChatGPTだけじゃない！便利なAIサービス10選
第７回：2025年、生成AIはどこまで進化する？
おまけ：2024年8月最新！生成AI用語集100

※関連ナレッジ資料※
生成AIで会議効率化！『文字起こし』と『議事録作成』始め方ガイド　をダウンロード

INDEX

1. 「生成AI」「LLM」「ChatGPT」とは？
2. 生成AIサービスの日本語対応と、日本語LLMについて
   「生成AI」「LLM」「ChatGPT」とは？
   最初に結論からいうと、「生成AI」は特定領域のAI技術の総称であり、そのAI技術の1つに「LLM（大規模言語モデル）」があり、「ChatGPT」はLLMを使って作られた生成AIサービス、となります。
   そのため構造としては大きい順番に「生成AI」＞「LLM（大規模言語モデル）」＞「ChatGPT」といった流れで考えると理解しやすいといえます。

＜出典：基本から分かる！「ChatGPT」＆「Microsoft Copilot」＆「Google Gemini」3大生成AI比較）＞

生成AI
生成AI（Generative AI）とは、人工知能（AI）技術の一種で、人間の脳のニューロン（神経細胞）のつながりや働きを模倣した「ニューラルネットワーク」と呼ばれる計算モデルを基盤としています。生成AIは、大量データ（テキスト・画像など）を学習することで、それらのデータに内在するパターンや特徴を自ら見つけ出し、理解することができます。

この特性により、生成AIは単にデータを分析するだけでなく、学習したデータを基にしたオリジナルのコンテンツを創造することも可能にしています。つまり生成AIは、既存のデータを学習して、そこから新しいテキストや画像、音声、動画などを自律的に生み出すことができるのです。
生成AIは、ビジネスの世界で大きな可能性を秘めています。例えば、顧客のニーズに合わせてパーソナライズされた商品やサービスを提供したり、効果的なマーケティングキャンペーンを立案したりすることができます。

LLM（大規模言語モデル）
LLM（Large Language Model）は、自然言語処理（NLP）に特化した人工知能（AI）技術の一種です。LLMは、インターネット上に存在する大量のテキストデータ（例えば、ニュース記事、書籍、ウェブサイトなど）を機械学習アルゴリズムを用いて解析し、言語の構造や意味、文脈などを理解します。
LLMの特徴は、その学習に使用されるテキストデータの膨大さにあります。LLMは、数百億から数兆語にも及ぶ大規模なテキストデータを学習することで、人間の言語の複雑さや微妙なニュアンスを捉えることができるようになり、人間のような自然な言語理解と言語生成を実現しています。

LLMの応用範囲は非常に広く、言語翻訳、文章要約、質問応答、感情分析、文章生成など、様々な分野で活用されています。例えば、外国語の文章を自動的に母国語に翻訳したり、長い文章を要約したり、質問に対する適切な回答を生成したりすることができます。
LLMは言語に関連する様々なタスクを自動化することで、私たちの生活やビジネスを大きく変える可能性を秘めています。LLMの登場により、言語の壁を越えたグローバルなコミュニケーションが促進され、知識やノウハウの共有がより一層進むことが期待されており、特に\*インターネット上の利用率が高い英語では、LLMの開発と発展が日本語などの他言語と比較して圧倒的なスピードで進んでいます。

\*参考：【インターネット言語】使用順位とシェア

ChatGPT
ChatGPTは、OpenAI社が開発した革新的な対話型AIシステムで、生成AI時代を象徴するサービスの一つです。ChatGPTは、LLM（Large Language Model）を基盤としており、膨大な量のテキストデータを学習することで、人間のような自然な会話を実現しています。

ChatGPTの最大の特徴は、その汎用性の高さにあります。一般的なトピックから専門的な内容まで幅広くカバーしており、例えば「健康的な食事について教えて」と質問すれば、バランスの取れた食事の重要性や具体的な食事プランを自分の代わりに考えてくれますし、「⚪︎⚪︎に関する最先端の技術について教えて」と質問すれば、インターネット上のコンテンツや世界中の学術論文から最新技術をピックアップして、わかりやすく解説してくれます。

ChatGPTは、​日本語をはじめとする自然言語だけでなく、ワードやエクセル、PDFを理解できることはもちろん、インターネット上の最新情報にアクセスしてユーザーの質問に回答できます。またAPI連携を利用することで、社内外のツールと相乗効果を発揮します。実際にビジネスシーンでの活用についても数多くの成功事例が生まれており、営業、マーケティング、カスタマーサポート、コンテンツ制作、社内の業務効率化など、幅広い業務範囲でユーザーをサポートすることが可能です。

生成AIサービスの日本語対応と、日本語LLMについて
主要な生成AIサービスのほとんどは日本語に対応しており、日本語で指示しても自然に動作します。しかしながら、多くの生成AIサービスが英語を中心に学習されているため、日本語ネイティブモデルとは異なる特性を持っています。この点を踏まえながら、日本語LLMの現状とChatGPTとの比較を見ていきましょう。

日本語ネイティブではないことに注意！
ChatGPTを含む多くの大規模言語モデルは、主に英語データを中心に学習されています。そのため日本語での使用時には、下記の点に注意が必要です。

1. 不自然な日本語表現：文法的には正しくても、ネイティブの日本語コミュニケーションとしては不自然な表現で応答することがあります。また日本語特有の専門用語や業界用語の理解が不十分な場合があります。ビジネスシーンで使われる和製英語や、英単語での略称（GAFAMなど）は誤解しやすいといえます。
2. 文化的背景理解が弱い：日本特有の文化や言語の特性に関する理解が不十分な場合があります。例えば「主語・述語の省略」「指示語の多用」「文章構造が前後する」といった日本語特有の文章構造を理解して処理することが苦手なため、複雑な指示を与える場合には、英語の文法に近い内容で記述することが求められます。

ChatGPTと比較した日本語LLMの現在地
ネガティブな事実として、日本語LLMの開発は急速に進んでいるものの、機能面の充実度や最新機能の導入速度など、ChatGPTに多くの優位性があります。具体的には、多くの日本語LLMはテキストのみの対応となっていますが、ChatGPTではテキスト生成だけでなく、画像理解などのマルチモーダル機能を無料版で利用することが可能です。

日本語LLMの開発には、学習データの不足、計算資源の制約、という2つの根本的な課題が存在します。日本語のデータ量は英語に比べるとわずかであり、LLM開発に使える学習データ量が絶対的に足りていないだけでなく、LLM開発に求められる高性能な計算資源（データセンター、スーパーコンピュータなど）も日本には不足しており、日本企業や研究機関がグローバル競争で遅れを取る一因となっています。グローバルな競争の中で、日本語LLMの開発は依然として多くの課題を抱えています。

まとめ
「生成AI」「ChatGPT」というキーワードが、今後もビジネスの主流に位置付けられることは疑いようがありません。その仕組みのすべてを理解する必要はありませんが、数年後、数十年後のビジネスシーンを考えた時、最低限のリテラシーを今から身につけておくことは重要です。
残念ながら日本独自の生成AIの現状は芳しくありませんが、米国発の生成AIサービスは日本語でも十分に機能するため、その動向からは目が離せません。

本連載を通じて、生成AIに対する「なんだかよくわからないもの」という印象を抜け出し、ビジネスだけでなく生活の場においても身近に感じられる一助になれば幸いです。
次回「今後の流れがわかる！米国ビッグテック企業と主要な生成AIサービス」もお見逃しなく！

<参考記事ここまで>

### 記事末尾の練習問題（jsonで出力）

コース記事末尾の練習問題は次の要素からなります。
これらの項目をjsonで出力してください。
複数の要素をリスト形式でまとめて出力してください。
なお、練習問題は必ず選択問題です。

```
- courseArticleId: コース記事公開時のurlのslugになるものです。既に記事のIDがここまでの情報から判定できる場合は、それをそのまま出力してください。（コースのIDではなく記事のIDです。）
- question： コース記事の内容を理解しているかどうかを試す質問文です。中にはコース記事の内容をすこし超えるような難しい問題をいれてもOKです。単に知識を問うだけでなく、コース記事内外の知識を組み合わせて思考しないと解けない問題もいれてください。
- options： 選択問題の選択肢です。["選択肢1","選択肢2","選択肢3","選択肢4"]のようなリスト形式の文字列で出力してください。（optionsの形式はリストではなくリスト形式の文字列です）
- correctAnswer： 選択問題の正解の選択肢です。選択肢2 のような文字列で出力してください。選択肢2というのはあくまで例で、実際は正解の選択肢と全く同じ文言を出力します。
```

## 出力に関する指示

出力はマークダウンとjson形式でそれぞれ出力してください。
なお、出力対象以外の余計な文言は出力しないでください。
