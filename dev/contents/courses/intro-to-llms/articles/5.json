[
  {
    "courseArticleId": "introduction-to-llm-fine-tuning",
    "question": "LLMファインチューニングの主な目的として正しいものは次のうちどれでしょうか？",
    "options": "[\"モデルの推論速度を極限まで上げるため\",\"定常的に学習データを収集し続けるため\",\"特定のタスクや文体に合わせモデルの出力を最適化するため\",\"RAGを完全に不要にするため\"]",
    "correctAnswer": "特定のタスクや文体に合わせモデルの出力を最適化するため"
  },
  {
    "courseArticleId": "introduction-to-llm-fine-tuning",
    "question": "ファインチューニングでは新しい事実を大量に学習させるのが困難とされる理由は何でしょうか？",
    "options": "[\"ファインチューニングするとモデルサイズが極端に小さくなるため\",\"モデルパラメータ数が増えるとAPIが利用不能になるため\",\"巨大モデルの知識ベースを根本から書き換えるには膨大なデータと学習時間が必要なため\",\"カスタムフォーマットの出力が安定しなくなるため\"]",
    "correctAnswer": "巨大モデルの知識ベースを根本から書き換えるには膨大なデータと学習時間が必要なため"
  },
  {
    "courseArticleId": "introduction-to-llm-fine-tuning",
    "question": "以下のうち、ファインチューニングによる効果が比較的期待しやすいタスクはどれでしょうか？",
    "options": "[\"数年後に起きる社会情勢の予測\",\"幻覚（ハルシネーション）の完全除去\",\"最新ニュースの逐次アップデート\",\"独自ルールや文体の厳格な適用\"]",
    "correctAnswer": "独自ルールや文体の厳格な適用"
  },
  {
    "courseArticleId": "introduction-to-llm-fine-tuning",
    "question": "RAGとファインチューニングの違いに関して正しい説明はどれでしょうか？",
    "options": "[\"RAGは大規模なGPUが必須だがファインチューニングは不要\",\"ファインチューニングは外部検索システムを構築しやすいがRAGでは難しい\",\"ファインチューニングではモデル自体を再学習し、RAGは外部データベースを検索して解決するアプローチ\",\"RAGはモデルをJSON形式で出力させる手法であり、ファインチューニングはテキスト出力しか行えない\"]",
    "correctAnswer": "ファインチューニングではモデル自体を再学習し、RAGは外部データベースを検索して解決するアプローチ"
  },
  {
    "courseArticleId": "introduction-to-llm-fine-tuning",
    "question": "ファインチューニングが学習データの品質に大きく依存する理由として最も適切なものはどれでしょうか？",
    "options": "[\"GPUリソースが使えない場合があるため\",\"ファインチューニング時に元のモデルが完全に破棄されるため\",\"学習データの不適切な回答例や誤情報がモデル挙動に直接反映されるため\",\"ファインチューニング後にはプロンプトが一切使えなくなるため\"]",
    "correctAnswer": "学習データの不適切な回答例や誤情報がモデル挙動に直接反映されるため"
  }
]